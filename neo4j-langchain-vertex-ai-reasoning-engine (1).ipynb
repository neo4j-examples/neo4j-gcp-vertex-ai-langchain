{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u4maG9UQ685"
      },
      "source": [
        "# GraphRAG with Neo4j and LangChain and Gemini on VertexAI Reasoning Engine\n",
        "\n",
        "This is a demonstration of a GeNAI API with advanced RAG patterns combining vector and graph search.\n",
        "\n",
        "It is deployed on Vertex AI Reasoning Engine (Preview) as scalable infrastructure and can then be integrated with GenAI applications on Cloud Run via REST APIs.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "The dataset is a graph about companies, associated industries, and people and articles that report on those companies.\n",
        "\n",
        "![Graph Model](https://i.imgur.com/lWJZSEe.png)\n",
        "\n",
        "The articles are chunked and the chunks also stored in the graph.\n",
        "\n",
        "Embeddings are computed for each of the text chunks with `textembedding-gecko` (786 dim) and stored on each chunk node.\n",
        "A Neo4j vector index `news_google` and a fulltext index `news_fulltext` (for hybrid search) were created.\n",
        "\n",
        "The database is publicly available with a readonly user:\n",
        "\n",
        "https://demo.neo4jlabs.com:7473/browser/\n",
        "\n",
        "* URI: neo4j+s://demo.neo4jlabs.com\n",
        "* User: companies\n",
        "* Password: companies\n",
        "* Companies: companies\n",
        "\n",
        "We utilize the Neo4jVector LangChain integration, which allows for advanced RAG patterns.\n",
        "We will utilize both hybrid search as well as parent-child retrievers and GraphRAG (extract relevant context).\n",
        "\n",
        "In our configuration we provide both the vector and fulltext index as well as a retrieval query that fetches the following additional information for each chunk\n",
        "\n",
        "* Parent `Article` of the `Chunk` (aggregate all chunks for a single article)\n",
        "* `Organization`(s) mentioned\n",
        "* `IndustryCategory`(ies) for the organization\n",
        "* `Person`(s) connected to the organization and their roles (e.g. investor, chairman, ceo)\n",
        "\n",
        "We will retrieve the top-k = 5 results from the vector index.\n",
        "\n",
        "As LLM we will utilize Vertex AI *Gemini Pro 1.0*\n",
        "\n",
        "We use a temperature of 0.1, top-k=40, top-p=0.8\n",
        "\n",
        "Our `LangchainCode` class contains the methods for initialization which can only hold serializable information (strings and numbers).\n",
        "\n",
        "In `set_up()` Gemini as LLM, VertexAI Embeddings and the `Neo4jVector` retriever are combined into a LangChain chain.\n",
        "\n",
        "Which is then used in `query`  with `chain.invoke()`.\n",
        "\n",
        "The class is deployed as ReasoningEngine with the Google Vertex AI Python SDK.\n",
        "For the deployment you provide the instance of the class which captures relevant environment variables and configuration and the dependencies, in our case `google-cloud-vertexai, langchain, langchain_google_vertexai, neo4j`.\n",
        "\n",
        "And after successful deploymnet we can use the resulting object via the `query` method, passing in our user question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 118,
          "status": "ok",
          "timestamp": 1716387442760,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "3mIXWnf_7Vtz"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"iamtests-315719\"\n",
        "REGION = \"us-central1\"\n",
        "STAGING_BUCKET = \"gs://neo4j-vertex-ai-extension2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2825,
          "status": "ok",
          "timestamp": 1716387446921,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "DW7SGmhwRyoJ",
        "outputId": "5def019d-fa0d-4790-bcb4-de3df28908f5"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user(project_id=PROJECT_ID)\n",
        "\n",
        "!gcloud config set project vertex-ai-neo4j-extension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxp09CthdF89"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet neo4j==5.19.0\n",
        "!pip install --quiet langchain_google_vertexai==1.0.4\n",
        "!pip install --quiet --force-reinstall langchain==0.2.0 langchain_community==0.2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 19630,
          "status": "ok",
          "timestamp": 1716386739685,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "9rpCl9j4Hpmh"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet google-cloud-aiplatform==1.51.0\n",
        "!pip install --quiet  google-cloud-resource-manager==1.12.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 226,
          "status": "ok",
          "timestamp": 1716393654282,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "guEu_Yh6Rv8n"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.preview import reasoning_engines\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "executionInfo": {
          "elapsed": 195,
          "status": "ok",
          "timestamp": 1716393656437,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mgNDGcXF-7zV"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEljoz48bw6E"
      },
      "source": [
        "If you installed any packages above, you can restart the runtime to pick them up:\n",
        "\n",
        "Click on the \"Runtime\" button at the top of Colab.\n",
        "Select \"Restart session\".\n",
        "You would not need to re-run the cell above this one (to reinstall the packages)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "executionInfo": {
          "elapsed": 114,
          "status": "ok",
          "timestamp": 1716393704640,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "Xbq3bR_Knf8k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "URI = os.getenv('NEO4J_URI', 'neo4j+s://demo.neo4jlabs.com')\n",
        "USER = os.getenv('NEO4J_USERNAME','companies')\n",
        "PASSWORD = os.getenv('NEO4J_PASSWORD','companies')\n",
        "DATABASE = os.getenv('NEO4J_DATABASE','companies')\n",
        "\n",
        "class LangchainCode:\n",
        "    def __init__(self):\n",
        "        self.model_name = \"gemini-1.5-pro-preview-0409\" #\"gemini-pro\"\n",
        "        self.max_output_tokens = 1024\n",
        "        self.temperature = 0.1\n",
        "        self.top_p = 0.8\n",
        "        self.top_k = 40\n",
        "        self.project_id = PROJECT_ID\n",
        "        self.location = REGION\n",
        "        self.uri = URI\n",
        "        self.username = USER\n",
        "        self.password = PASSWORD\n",
        "        self.database = DATABASE\n",
        "        self.prompt_input_variables = [\"query\"]\n",
        "        self.prompt_template=\"\"\"\n",
        "            You are a venture capital assistant that provides useful answers about companies, their boards, financing etc.\n",
        "            only using the information from a company database already provided in the context.\n",
        "            Prefer higher rated information in your context and add source links in your answers.\n",
        "            Context: {context}\"\"\"\n",
        "\n",
        "    def configure_qa_rag_chain(self, llm, embeddings):\n",
        "        qa_prompt = ChatPromptTemplate.from_messages([\n",
        "            SystemMessagePromptTemplate.from_template(self.prompt_template),\n",
        "            HumanMessagePromptTemplate.from_template(\"Question: {question}\"\n",
        "                                                      \"\\nWhat else can you tell me about it?\"),\n",
        "        ])\n",
        "\n",
        "        # Vector + Knowledge Graph response\n",
        "        kg = Neo4jVector.from_existing_index(\n",
        "            embedding=embeddings,\n",
        "            url=self.uri, username=self.username, password=self.password,database=self.database,\n",
        "            search_type=\"hybrid\",\n",
        "            keyword_index_name=\"news_fulltext\",\n",
        "            index_name=\"news_google\",\n",
        "            retrieval_query=\"\"\"\n",
        "              WITH node as c,score\n",
        "              MATCH (c)<-[:HAS_CHUNK]-(article:Article)\n",
        "\n",
        "              WITH article, collect(distinct c.text) as texts, avg(score) as score\n",
        "              RETURN article {.title, .sentiment, .siteName, .summary,\n",
        "                    organizations: [ (article)-[:MENTIONS]->(org:Organization) |\n",
        "                          org { .name, .revenue, .nbrEmployees, .isPublic, .motto, .summary,\n",
        "                          orgCategories: [ (org)-[:HAS_CATEGORY]->(i) | i.name],\n",
        "                          people: [ (org)-[rel]->(p:Person) | p { .name, .summary, role: replace(type(rel),\"HAS_\",\"\") }]}],\n",
        "                    texts: texts} as text,\n",
        "              score, {source: article.siteName} as metadata\n",
        "            \"\"\",\n",
        "        )\n",
        "        retriever = kg.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "        def format_docs(docs):\n",
        "          return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "        chain = (\n",
        "            {\"context\": retriever | format_docs , \"question\": RunnablePassthrough()}\n",
        "            | qa_prompt\n",
        "            | llm\n",
        "            | StrOutputParser()\n",
        "        )\n",
        "        return chain\n",
        "\n",
        "    def set_up(self):\n",
        "        from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "        from langchain_google_vertexai import VertexAIEmbeddings, ChatVertexAI\n",
        "        from langchain_community.vectorstores import Neo4jVector\n",
        "        from langchain_core.output_parsers import StrOutputParser\n",
        "        from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "        self.llm = ChatVertexAI(\n",
        "            model_name=self.model_name,\n",
        "            max_output_tokens=self.max_output_tokens,\n",
        "            max_input_tokens=32000,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            project = self.project_id,\n",
        "            location = self.location,\n",
        "            # convert_system_message_to_human=True,\n",
        "            response_validation=False,\n",
        "            verbose=True\n",
        "        )\n",
        "        self.embeddings = VertexAIEmbeddings(\"textembedding-gecko@001\")\n",
        "\n",
        "        self.qa_chain = self.configure_qa_rag_chain(self.llm, self.embeddings)\n",
        "\n",
        "    def query(self, query):\n",
        "        from langchain.agents import initialize_agent\n",
        "        from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
        "\n",
        "        # conversational memory\n",
        "        conversational_memory = ConversationBufferWindowMemory(\n",
        "            memory_key='chat_history',\n",
        "            k=0,\n",
        "            return_messages=True\n",
        "        )\n",
        "\n",
        "        from langchain.agents import Tool\n",
        "\n",
        "        tools = [\n",
        "            Tool(\n",
        "                name='Knowledge Base',\n",
        "                func=self.qa_chain.invoke,\n",
        "                description=(\n",
        "                    'use this tool when answering specific news queries to get '\n",
        "                    'more information about the topic'\n",
        "                )\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        agent = initialize_agent(\n",
        "            agent='chat-conversational-react-description',\n",
        "            tools=tools,\n",
        "            llm=self.llm,\n",
        "            verbose=True,\n",
        "            max_iterations=3,\n",
        "            early_stopping_method='generate',\n",
        "            memory=conversational_memory\n",
        "        )\n",
        "        return agent(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "executionInfo": {
          "elapsed": 149,
          "status": "ok",
          "timestamp": 1716303465137,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "PfUcIghUElzt"
      },
      "outputs": [],
      "source": [
        "from langchain.globals import set_debug\n",
        "set_debug(False)\n",
        "\n",
        "# testing locally\n",
        "lc = LangchainCode()\n",
        "lc.set_up()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            " \"action\": \"Final Answer\",\n",
            " \"action_input\": \"2 x 5 = 10\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'What is 2x5?', 'chat_history': [], 'output': '2 x 5 = 10'}\n"
          ]
        }
      ],
      "source": [
        "response = lc.query('What is 2x5?')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 12077,
          "status": "ok",
          "timestamp": 1716396587908,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "W4h6EQ89HlKR",
        "outputId": "14b0c809-5d65-4d32-ca5b-a49a186b0322"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Knowledge Base\",\n",
            "    \"action_input\": \"Recent IBM acquisitions and key people involved\"\n",
            "}\n",
            "```\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mIBM acquired the following companies: SPSS [source](domain-b.com), Ounce Labs [source](domain-b.com), Ascential Software [source](CHINAdaily.com.cn), Cognos [source](CHINAdaily.com.cn), Netezza [source](CHINAdaily.com.cn), OpenPages [source](CHINAdaily.com.cn), Softek Storage Solutions [source](Information Technology Planning, Implementation and IT Solutions for Business - News & Reviews - BaselineMag.com), DWL [source](MarketWatch), and Lombardi Software [source](MC Press Online).\n",
            "\n",
            "Key people involved in these acquisitions include:\n",
            "\n",
            "* **IBM:**\n",
            "    * Arvind Krishna (CEO) [source](CHINAdaily.com.cn)\n",
            "    * Bill Kelleher (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Michael L. Eskew (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Mark Ritter (Chairman) [source](CHINAdaily.com.cn)\n",
            "    * George Eapen (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Christina Montgomery (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Michelle Howard (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Al Zollar (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Ginni Rometty (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Thomas Buberl (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * William McNabb (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Martha E. Pollack (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Peter Voser (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Joseph Swedish (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Andrew N. Liveris (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Gary Cohn (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Frederick Waddell (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Alex Gorsky (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * David Farr (Board Member) [source](CHINAdaily.com.cn)\n",
            "* **SPSS:**\n",
            "    * Christopher Bloise (Board Member) [source](domain-b.com)\n",
            "* **Netezza:**\n",
            "    * Edward Zander (Board Member) [source](CHINAdaily.com.cn)\n",
            "    * Barry Zane (Board Member) [source](CHINAdaily.com.cn)\n",
            "* **Cognos:**\n",
            "    * Robert Willem Korthals \"Robin\" (Board Member) [source](CHINAdaily.com.cn)\n",
            "* **DWL:**\n",
            "    * Ten-Squared (Investor) [source](MarketWatch)\n",
            "    * Robert A Shafto (Board Member) [source](MarketWatch)\n",
            "    * John McNeil (Board Member) [source](MarketWatch)\n",
            "* **Lombardi Software:**\n",
            "    * Jim Gauer (Board Member) [source](MC Press Online)\n",
            "\n",
            "\n",
            "\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Based on information I have found, IBM acquired several companies, including SPSS, Ounce Labs, Ascential Software, Cognos, Netezza, OpenPages, Softek Storage Solutions, DWL, and Lombardi Software. Key people involved in these acquisitions include Arvind Krishna (IBM's CEO), as well as board members from both IBM and the acquired companies.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'What are the news about IBM and its acquisitions and who are the people involved?', 'chat_history': [], 'output': \"Based on information I have found, IBM acquired several companies, including SPSS, Ounce Labs, Ascential Software, Cognos, Netezza, OpenPages, Softek Storage Solutions, DWL, and Lombardi Software. Key people involved in these acquisitions include Arvind Krishna (IBM's CEO), as well as board members from both IBM and the acquired companies.\"}\n"
          ]
        }
      ],
      "source": [
        "response = lc.query('What are the news about IBM and its acquisitions and who are the people involved?')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 223162,
          "status": "ok",
          "timestamp": 1716393943730,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "x6b4zSDDsUuw",
        "outputId": "87f17308-3ea3-48a8-e6a4-4d49df785096"
      },
      "outputs": [],
      "source": [
        "remote_app = reasoning_engines.ReasoningEngine.create(\n",
        "    LangchainCode(),\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform==1.51.0\",\n",
        "        \"langchain_google_vertexai==1.0.4\",\n",
        "        \"langchain==0.2.0\",\n",
        "        \"langchain_community==0.2.0\",\n",
        "        \"neo4j==5.19.0\"\n",
        "    ],\n",
        "    display_name=\"Neo4j Vertex AI RE Companies\",\n",
        "    description=\"Neo4j Vertex AI RE Companies\",\n",
        "    sys_version=\"3.10\",\n",
        "    extra_packages=[]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 20866,
          "status": "ok",
          "timestamp": 1716393964595,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "hF95dtx-sXpT",
        "outputId": "e8370694-6fd9-461e-8aa3-2af1a8003ca1"
      },
      "outputs": [],
      "source": [
        "response = remote_app.query(query=\"Who is on the board of Siemens?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "vertexAIreasoning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
