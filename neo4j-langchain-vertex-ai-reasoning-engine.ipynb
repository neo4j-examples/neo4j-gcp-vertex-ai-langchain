{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6u4maG9UQ685"
      },
      "source": [
        "# GraphRAG with Neo4j and LangChain and Gemini on VertexAI Reasoning Engine\n",
        "\n",
        "This is a demonstration of a GeNAI API with advanced RAG patterns combining vector and graph search.\n",
        "\n",
        "It is deployed on Vertex AI Reasoning Engine (Preview) as scalable infrastructure and can then be integrated with GenAI applications on Cloud Run via REST APIs.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "The dataset is a graph about companies, associated industries, and people and articles that report on those companies.\n",
        "\n",
        "![Graph Model](https://i.imgur.com/lWJZSEe.png)\n",
        "\n",
        "The articles are chunked and the chunks also stored in the graph.\n",
        "\n",
        "Embeddings are computed for each of the text chunks with `textembedding-gecko` (786 dim) and stored on each chunk node.\n",
        "A Neo4j vector index `news_google` and a fulltext index `news_fulltext` (for hybrid search) were created.\n",
        "\n",
        "The database is publicly available with a readonly user:\n",
        "\n",
        "https://demo.neo4jlabs.com:7473/browser/\n",
        "\n",
        "* URI: neo4j+s://demo.neo4jlabs.com\n",
        "* User: companies\n",
        "* Password: companies\n",
        "* Companies: companies\n",
        "\n",
        "We utilize the Neo4jVector LangChain integration, which allows for advanced RAG patterns.\n",
        "We will utilize both hybrid search as well as parent-child retrievers and GraphRAG (extract relevant context).\n",
        "\n",
        "In our configuration we provide both the vector and fulltext index as well as a retrieval query that fetches the following additional information for each chunk\n",
        "\n",
        "* Parent `Article` of the `Chunk` (aggregate all chunks for a single article)\n",
        "* `Organization`(s) mentioned\n",
        "* `IndustryCategory`(ies) for the organization\n",
        "* `Person`(s) connected to the organization and their roles (e.g. investor, chairman, ceo)\n",
        "\n",
        "We will retrieve the top-k = 5 results from the vector index.\n",
        "\n",
        "As LLM we will utilize Vertex AI *Gemini Pro 1.0*\n",
        "\n",
        "We use a temperature of 0.1, top-k=40, top-p=0.8\n",
        "\n",
        "Our `LangchainCode` class contains the methods for initialization which can only hold serializable information (strings and numbers).\n",
        "\n",
        "In `set_up()` Gemini as LLM, VertexAI Embeddings and the `Neo4jVector` retriever are combined into a LangChain chain.\n",
        "\n",
        "Which is then used in `query`  with `chain.invoke()`.\n",
        "\n",
        "The class is deployed as ReasoningEngine with the Google Vertex AI Python SDK.\n",
        "For the deployment you provide the instance of the class which captures relevant environment variables and configuration and the dependencies, in our case `google-cloud-vertexai, langchain, langchain_google_vertexai, neo4j`.\n",
        "\n",
        "And after successful deploymnet we can use the resulting object via the `query` method, passing in our user question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "executionInfo": {
          "elapsed": 118,
          "status": "ok",
          "timestamp": 1716387442760,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "3mIXWnf_7Vtz"
      },
      "outputs": [],
      "source": [
        "PROJECT_ID = \"iamtests-315719\"\n",
        "REGION = \"us-central1\"\n",
        "STAGING_BUCKET = \"gs://neo4j-vertex-ai-extension2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 2825,
          "status": "ok",
          "timestamp": 1716387446921,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "DW7SGmhwRyoJ",
        "outputId": "5def019d-fa0d-4790-bcb4-de3df28908f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import auth\n",
        "# auth.authenticate_user(project_id=PROJECT_ID)\n",
        "\n",
        "!gcloud config set project $PROJECT_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxp09CthdF89"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet neo4j==5.19.0\n",
        "!pip install --quiet langchain_google_vertexai==1.0.4\n",
        "!pip install --quiet --force-reinstall langchain==0.2.0 langchain_community==0.2.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {
          "elapsed": 19630,
          "status": "ok",
          "timestamp": 1716386739685,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "9rpCl9j4Hpmh"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet google-cloud-aiplatform==1.51.0\n",
        "!pip install --quiet  google-cloud-resource-manager==1.12.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "executionInfo": {
          "elapsed": 226,
          "status": "ok",
          "timestamp": 1716393654282,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "guEu_Yh6Rv8n"
      },
      "outputs": [],
      "source": [
        "import vertexai\n",
        "from vertexai.preview import reasoning_engines\n",
        "\n",
        "vertexai.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    staging_bucket=STAGING_BUCKET,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "executionInfo": {
          "elapsed": 195,
          "status": "ok",
          "timestamp": 1716393656437,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "mgNDGcXF-7zV"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "from langchain_google_vertexai import ChatVertexAI, VertexAIEmbeddings\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEljoz48bw6E"
      },
      "source": [
        "If you installed any packages above, you can restart the runtime to pick them up:\n",
        "\n",
        "Click on the \"Runtime\" button at the top of Colab.\n",
        "Select \"Restart session\".\n",
        "You would not need to re-run the cell above this one (to reinstall the packages)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "executionInfo": {
          "elapsed": 114,
          "status": "ok",
          "timestamp": 1716393704640,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "Xbq3bR_Knf8k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Callable, Sequence\n",
        "\n",
        "URI = os.getenv('NEO4J_URI', 'neo4j+s://demo.neo4jlabs.com')\n",
        "USER = os.getenv('NEO4J_USERNAME','companies')\n",
        "PASSWORD = os.getenv('NEO4J_PASSWORD','companies')\n",
        "DATABASE = os.getenv('NEO4J_DATABASE','companies')\n",
        "\n",
        "class LangchainCode:\n",
        "    def __init__(\n",
        "            self,\n",
        "            model: str,\n",
        "            tools: Sequence[Callable],\n",
        "        ):\n",
        "        self.model_name = model #\"gemini-pro\"\n",
        "        self.max_output_tokens = 1024\n",
        "        self.temperature = 0.1\n",
        "        self.top_p = 0.8\n",
        "        self.top_k = 40\n",
        "        self.project_id = PROJECT_ID\n",
        "        self.location = REGION\n",
        "        self.tools = tools\n",
        "        self.uri = URI\n",
        "        self.username = USER\n",
        "        self.password = PASSWORD\n",
        "        self.database = DATABASE\n",
        "        self.prompt_input_variables = [\"query\"]\n",
        "        self.prompt_template=\"\"\"\n",
        "            You are a venture capital assistant that provides useful answers about companies, their boards, financing etc.\n",
        "            only using the information from a company database already provided in the context.\n",
        "            Prefer higher rated information in your context and add source links in your answers.\n",
        "            Context: {context}\"\"\"\n",
        "\n",
        "    def set_up(self):\n",
        "        from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate\n",
        "        from langchain_google_vertexai import VertexAIEmbeddings, ChatVertexAI\n",
        "        from langchain_community.vectorstores import Neo4jVector\n",
        "        from langchain_core.output_parsers import StrOutputParser\n",
        "        from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
        "\n",
        "        # agents module\n",
        "        from langchain_google_vertexai import ChatVertexAI\n",
        "        from langchain.agents import AgentExecutor\n",
        "        from langchain.agents.format_scratchpad.tools import format_to_tool_messages\n",
        "        from langchain.agents.output_parsers.tools import ToolsAgentOutputParser\n",
        "        from langchain.tools.base import StructuredTool\n",
        "        from langchain_core import prompts\n",
        "\n",
        "        llm = ChatVertexAI(\n",
        "            model_name=self.model_name,\n",
        "            max_output_tokens=self.max_output_tokens,\n",
        "            max_input_tokens=32000,\n",
        "            temperature=self.temperature,\n",
        "            top_p=self.top_p,\n",
        "            top_k=self.top_k,\n",
        "            project = self.project_id,\n",
        "            location = self.location,\n",
        "            # convert_system_message_to_human=True,\n",
        "            response_validation=False,\n",
        "            verbose=True\n",
        "        )\n",
        "        if self.tools:\n",
        "            llm = llm.bind_tools(tools=self.tools)\n",
        "\n",
        "        embeddings = VertexAIEmbeddings(\"textembedding-gecko@001\")\n",
        "        \n",
        "        # agent block\n",
        "        prompt = {\n",
        "            \"input\": lambda x: x[\"input\"],\n",
        "            \"agent_scratchpad\": (\n",
        "                lambda x: format_to_tool_messages(x[\"intermediate_steps\"])\n",
        "            ),\n",
        "        } | prompts.ChatPromptTemplate.from_messages([\n",
        "            (\"user\", \"{input}\"),\n",
        "            prompts.MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "        ])\n",
        "        self.agent_executor = AgentExecutor(\n",
        "            agent=prompt | llm | ToolsAgentOutputParser(),\n",
        "            tools=[StructuredTool.from_function(tool) for tool in self.tools],\n",
        "        )\n",
        "\n",
        "        # self.qa_chain = self.configure_qa_rag_chain(llm, embeddings)\n",
        "\n",
        "    def query(self, input: str):\n",
        "        '''Query the application.\n",
        "\n",
        "        Args:\n",
        "            input: The user prompt.\n",
        "\n",
        "        Returns:\n",
        "            The output of querying the application with the given input.\n",
        "        '''\n",
        "        # return self.qa_chain.invoke(query)\n",
        "        return self.agent_executor.invoke(input={\"input\": input})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create this function as a tool\n",
        "def configure_qa_rag_chain(self, llm, embeddings):\n",
        "    '''\n",
        "    docstring\n",
        "    '''\n",
        "    qa_prompt = ChatPromptTemplate.from_messages([\n",
        "        SystemMessagePromptTemplate.from_template(self.prompt_template),\n",
        "        HumanMessagePromptTemplate.from_template(\"Question: {question}\"\n",
        "                                                    \"\\nWhat else can you tell me about it?\"),\n",
        "    ])\n",
        "\n",
        "    # Vector + Knowledge Graph response\n",
        "    kg = Neo4jVector.from_existing_index(\n",
        "        embedding=embeddings,\n",
        "        url=self.uri, username=self.username, password=self.password,database=self.database,\n",
        "        search_type=\"hybrid\",\n",
        "        keyword_index_name=\"news_fulltext\",\n",
        "        index_name=\"news_google\",\n",
        "        retrieval_query=\"\"\"\n",
        "            WITH node as c,score\n",
        "            MATCH (c)<-[:HAS_CHUNK]-(article:Article)\n",
        "\n",
        "            WITH article, collect(distinct c.text) as texts, avg(score) as score\n",
        "            RETURN article {.title, .sentiment, .siteName, .summary,\n",
        "                organizations: [ (article)-[:MENTIONS]->(org:Organization) |\n",
        "                        org { .name, .revenue, .nbrEmployees, .isPublic, .motto, .summary,\n",
        "                        orgCategories: [ (org)-[:HAS_CATEGORY]->(i) | i.name],\n",
        "                        people: [ (org)-[rel]->(p:Person) | p { .name, .summary, role: replace(type(rel),\"HAS_\",\"\") }]}],\n",
        "                texts: texts} as text,\n",
        "            score, {source: article.siteName} as metadata\n",
        "        \"\"\",\n",
        "    )\n",
        "    retriever = kg.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "    def format_docs(docs):\n",
        "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "    chain = (\n",
        "        {\"context\": retriever | format_docs , \"question\": RunnablePassthrough()}\n",
        "        | qa_prompt\n",
        "        | llm\n",
        "        | StrOutputParser()\n",
        "    )\n",
        "    return chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "executionInfo": {
          "elapsed": 149,
          "status": "ok",
          "timestamp": 1716303465137,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "PfUcIghUElzt"
      },
      "outputs": [],
      "source": [
        "from langchain.globals import set_debug\n",
        "set_debug(False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 12077,
          "status": "ok",
          "timestamp": 1716396587908,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "W4h6EQ89HlKR",
        "outputId": "14b0c809-5d65-4d32-ca5b-a49a186b0322"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised InvalidArgument: 400 Unable to submit request because one or more function parameters didn't specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling.\n",
            "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised InvalidArgument: 400 Unable to submit request because one or more function parameters didn't specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling.\n",
            "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 4.0 seconds as it raised InvalidArgument: 400 Unable to submit request because one or more function parameters didn't specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling.\n",
            "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 8.0 seconds as it raised InvalidArgument: 400 Unable to submit request because one or more function parameters didn't specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling.\n",
            "Retrying langchain_google_vertexai.chat_models._completion_with_retry.<locals>._completion_with_retry_inner in 10.0 seconds as it raised InvalidArgument: 400 Unable to submit request because one or more function parameters didn't specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling.\n"
          ]
        },
        {
          "ename": "InvalidArgument",
          "evalue": "400 Unable to submit request because one or more function parameters didn't specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:170\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m     prefetch_first \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(callable_, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_prefetch_first_result_\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_StreamingResponseIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefetch_first_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefetch_first\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:92\u001b[0m, in \u001b[0;36m_StreamingResponseIterator.__init__\u001b[0;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m prefetch_first_result:\n\u001b[0;32m---> 92\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stored_first_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;66;03m# It is possible the wrapped method isn't an iterable (a grpc.Call\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# for instance). If this happens don't store the first result.\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/grpc/_channel.py:475\u001b[0m, in \u001b[0;36m_Rendezvous.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/grpc/_channel.py:881\u001b[0m, in \u001b[0;36m_MultiThreadedRendezvous._next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 881\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.INVALID_ARGUMENT\n\tdetails = \"Unable to submit request because one or more function parameters didn't specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:142.251.33.170:443 {grpc_message:\"Unable to submit request because one or more function parameters didn\\'t specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling\", grpc_status:3, created_time:\"2024-06-25T14:08:24.636582-07:00\"}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[73], line 8\u001b[0m\n\u001b[1;32m      2\u001b[0m lc \u001b[38;5;241m=\u001b[39m LangchainCode(\n\u001b[1;32m      3\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemini-1.5-pro-preview-0409\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     tools\u001b[38;5;241m=\u001b[39m[configure_qa_rag_chain]\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m lc\u001b[38;5;241m.\u001b[39mset_up()\n\u001b[0;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mlc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWhat are the news about IBM and its acquisitions and who are the people involved?\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
            "Cell \u001b[0;32mIn[67], line 94\u001b[0m, in \u001b[0;36mLangchainCode.query\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Query the application.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    The output of querying the application with the given input.\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# return self.qa_chain.invoke(query)\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain/chains/base.py:166\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    165\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    167\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain/chains/base.py:156\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    155\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    159\u001b[0m     )\n\u001b[1;32m    161\u001b[0m     final_outputs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    162\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain/agents/agent.py:1433\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1432\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1433\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1436\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1438\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1442\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1443\u001b[0m         )\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain/agents/agent.py:1139\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1132\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1139\u001b[0m         [\n\u001b[1;32m   1140\u001b[0m             a\n\u001b[1;32m   1141\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1142\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1143\u001b[0m                 color_mapping,\n\u001b[1;32m   1144\u001b[0m                 inputs,\n\u001b[1;32m   1145\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1146\u001b[0m                 run_manager,\n\u001b[1;32m   1147\u001b[0m             )\n\u001b[1;32m   1148\u001b[0m         ]\n\u001b[1;32m   1149\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain/agents/agent.py:1139\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1132\u001b[0m     name_to_tool_map: Dict[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1137\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, List[Tuple[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1139\u001b[0m         [\n\u001b[1;32m   1140\u001b[0m             a\n\u001b[1;32m   1141\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_next_step(\n\u001b[1;32m   1142\u001b[0m                 name_to_tool_map,\n\u001b[1;32m   1143\u001b[0m                 color_mapping,\n\u001b[1;32m   1144\u001b[0m                 inputs,\n\u001b[1;32m   1145\u001b[0m                 intermediate_steps,\n\u001b[1;32m   1146\u001b[0m                 run_manager,\n\u001b[1;32m   1147\u001b[0m             )\n\u001b[1;32m   1148\u001b[0m         ]\n\u001b[1;32m   1149\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain/agents/agent.py:1167\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain/agents/agent.py:515\u001b[0m, in \u001b[0;36mRunnableMultiActionAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m final_output: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream_runnable:\n\u001b[1;32m    509\u001b[0m     \u001b[38;5;66;03m# Use streaming to make sure that the underlying LLM is invoked in a\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;66;03m# streaming\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;66;03m# Because the response from the plan is not a generator, we need to\u001b[39;00m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;66;03m# accumulate the output into final output and return that.\u001b[39;00m\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunnable\u001b[38;5;241m.\u001b[39mstream(inputs, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}):\n\u001b[1;32m    516\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    517\u001b[0m             final_output \u001b[38;5;241m=\u001b[39m chunk\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:2882\u001b[0m, in \u001b[0;36mRunnableSequence.stream\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2876\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m(\n\u001b[1;32m   2877\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2878\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   2879\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2880\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2881\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2882\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28miter\u001b[39m([\u001b[38;5;28minput\u001b[39m]), config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:2869\u001b[0m, in \u001b[0;36mRunnableSequence.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   2864\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2865\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   2866\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2867\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   2868\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 2869\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_stream_with_config(\n\u001b[1;32m   2870\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2871\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform,\n\u001b[1;32m   2872\u001b[0m         patch_config(config, run_name\u001b[38;5;241m=\u001b[39m(config \u001b[38;5;129;01mor\u001b[39;00m {})\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m   2873\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2874\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:1867\u001b[0m, in \u001b[0;36mRunnable._transform_stream_with_config\u001b[0;34m(self, input, transformer, config, run_type, **kwargs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1867\u001b[0m         chunk: Output \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1868\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n\u001b[1;32m   1869\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m final_output_supported:\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:2831\u001b[0m, in \u001b[0;36mRunnableSequence._transform\u001b[0;34m(self, input, run_manager, config, **kwargs)\u001b[0m\n\u001b[1;32m   2828\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2829\u001b[0m         final_pipeline \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39mtransform(final_pipeline, config)\n\u001b[0;32m-> 2831\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m final_pipeline:\n\u001b[1;32m   2832\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m output\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:1163\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m final: Input\n\u001b[1;32m   1161\u001b[0m got_first_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ichunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;66;03m# The default implementation of transform is to buffer input and\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     \u001b[38;5;66;03m# then call stream.\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m     \u001b[38;5;66;03m# It'll attempt to gather all input into a single chunk using\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;66;03m# the `+` operator.\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m     \u001b[38;5;66;03m# If the input is not addable, then we'll assume that we can\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m     \u001b[38;5;66;03m# only operate on the last chunk,\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m     \u001b[38;5;66;03m# and we'll iterate until we get to the last chunk.\u001b[39;00m\n\u001b[1;32m   1171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m got_first_val:\n\u001b[1;32m   1172\u001b[0m         final \u001b[38;5;241m=\u001b[39m ichunk\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:4784\u001b[0m, in \u001b[0;36mRunnableBindingBase.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\n\u001b[1;32m   4779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4780\u001b[0m     \u001b[38;5;28minput\u001b[39m: Iterator[Input],\n\u001b[1;32m   4781\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4782\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   4783\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Output]:\n\u001b[0;32m-> 4784\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   4785\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   4786\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   4787\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   4788\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/runnables/base.py:1181\u001b[0m, in \u001b[0;36mRunnable.transform\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   1178\u001b[0m             final \u001b[38;5;241m=\u001b[39m ichunk\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m got_first_val:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(final, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:265\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    259\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(\n\u001b[1;32m    260\u001b[0m         e,\n\u001b[1;32m    261\u001b[0m         response\u001b[38;5;241m=\u001b[39mLLMResult(\n\u001b[1;32m    262\u001b[0m             generations\u001b[38;5;241m=\u001b[39m[[generation]] \u001b[38;5;28;01mif\u001b[39;00m generation \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    263\u001b[0m         ),\n\u001b[1;32m    264\u001b[0m     )\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_llm_end(LLMResult(generations\u001b[38;5;241m=\u001b[39m[[generation]]))\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:245\u001b[0m, in \u001b[0;36mBaseChatModel.stream\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    243\u001b[0m generation: Optional[ChatGenerationChunk] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m             chunk\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun_manager\u001b[38;5;241m.\u001b[39mrun_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py:921\u001b[0m, in \u001b[0;36mChatVertexAI._stream\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_non_gemini(\n\u001b[1;32m    918\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    919\u001b[0m     )\n\u001b[1;32m    920\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_gemini(\n\u001b[1;32m    922\u001b[0m     messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    923\u001b[0m )\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py:934\u001b[0m, in \u001b[0;36mChatVertexAI._stream_gemini\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream_gemini\u001b[39m(\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    928\u001b[0m     messages: List[BaseMessage],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    932\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[ChatGenerationChunk]:\n\u001b[1;32m    933\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request_gemini(messages\u001b[38;5;241m=\u001b[39mmessages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 934\u001b[0m     response_iter \u001b[38;5;241m=\u001b[39m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream_generate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_gemini\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response_chunk \u001b[38;5;129;01min\u001b[39;00m response_iter:\n\u001b[1;32m    942\u001b[0m         chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gemini_chunk_to_generation_chunk(response_chunk)\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py:496\u001b[0m, in \u001b[0;36m_completion_with_retry\u001b[0;34m(generation_method, max_retries, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    491\u001b[0m params \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    492\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_gemini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[1;32m    495\u001b[0m )\n\u001b[0;32m--> 496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_completion_with_retry_inner\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/tenacity/__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/tenacity/__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/tenacity/__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/tenacity/__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/tenacity/__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/tenacity/__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/langchain_google_vertexai/chat_models.py:489\u001b[0m, in \u001b[0;36m_completion_with_retry.<locals>._completion_with_retry_inner\u001b[0;34m(generation_method, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_completion_with_retry_inner\u001b[39m(generation_method: Callable, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/google/cloud/aiplatform_v1beta1/services/prediction_service/client.py:2228\u001b[0m, in \u001b[0;36mPredictionServiceClient.stream_generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m   2227\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m-> 2228\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2231\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2232\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2235\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/usr/local/anaconda3/lib/python3.10/site-packages/google/api_core/grpc_helpers.py:174\u001b[0m, in \u001b[0;36m_wrap_stream_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StreamingResponseIterator(\n\u001b[1;32m    171\u001b[0m         result, prefetch_first_result\u001b[38;5;241m=\u001b[39mprefetch_first\n\u001b[1;32m    172\u001b[0m     )\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 174\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
            "\u001b[0;31mInvalidArgument\u001b[0m: 400 Unable to submit request because one or more function parameters didn't specify the schema type field. Learn more: https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/function-calling"
          ]
        }
      ],
      "source": [
        "# testing locally\n",
        "lc = LangchainCode(\n",
        "    model=\"gemini-1.5-pro-preview-0409\",\n",
        "    tools=[configure_qa_rag_chain]\n",
        ")\n",
        "lc.set_up()\n",
        "\n",
        "response = lc.query('What are the news about IBM and its acquisitions and who are the people involved?')\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 223162,
          "status": "ok",
          "timestamp": 1716393943730,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "x6b4zSDDsUuw",
        "outputId": "87f17308-3ea3-48a8-e6a4-4d49df785096"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:vertexai.reasoning_engines._reasoning_engines:Using bucket neo4j-vertex-ai-extension\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://neo4j-vertex-ai-extension/reasoning_engine/reasoning_engine.pkl\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://neo4j-vertex-ai-extension/reasoning_engine/requirements.txt\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Creating in-memory tarfile of extra_packages\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Writing to gs://neo4j-vertex-ai-extension/reasoning_engine/dependencies.tar.gz\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Creating ReasoningEngine\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:Create ReasoningEngine backing LRO: projects/990868019953/locations/us-central1/reasoningEngines/7289005628154970112/operations/3531746006863446016\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:ReasoningEngine created. Resource name: projects/990868019953/locations/us-central1/reasoningEngines/7289005628154970112\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:To use this ReasoningEngine in another session:\n",
            "INFO:vertexai.reasoning_engines._reasoning_engines:reasoning_engine = vertexai.preview.reasoning_engines.ReasoningEngine('projects/990868019953/locations/us-central1/reasoningEngines/7289005628154970112')\n"
          ]
        }
      ],
      "source": [
        "remote_app = reasoning_engines.ReasoningEngine.create(\n",
        "    LangchainCode(),\n",
        "    requirements=[\n",
        "        \"google-cloud-aiplatform==1.51.0\",\n",
        "        \"langchain_google_vertexai==1.0.4\",\n",
        "        \"langchain==0.2.0\",\n",
        "        \"langchain_community==0.2.0\",\n",
        "        \"neo4j==5.19.0\"\n",
        "    ],\n",
        "    display_name=\"Neo4j Vertex AI RE Companies\",\n",
        "    description=\"Neo4j Vertex AI RE Companies\",\n",
        "    sys_version=\"3.10\",\n",
        "    extra_packages=[]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "executionInfo": {
          "elapsed": 20866,
          "status": "ok",
          "timestamp": 1716393964595,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": -120
        },
        "id": "hF95dtx-sXpT",
        "outputId": "e8370694-6fd9-461e-8aa3-2af1a8003ca1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The board of Siemens is composed of:\n",
            "\n",
            "* Jim Hagemann Snabe (Manager and chairman) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Dominika Bettman (CEO at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Alejandro Preinfalk (CEO at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Miguel Angel Lopez Borrego (CEO at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Hanna Hennig (CIO at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Barbara Humpton (CEO at Siemens Bank) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Matthias Rebellius (CEO at Siemens Corporate Technology) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Cedrik Neike (CEO at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Ralf P. Thomas (CFO at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Michael Sigmund (Chairman at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Horst J. Kayser (Chairman at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Michael Diekmann (Business person) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Norbert Reithofer (German businessman) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Werner Brandt (German manager) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "* Birgit Steinborn (Chairman at Siemens) [source](https://automation.com/story/184274/siemens-brings-real-time-supply-chain-intelligence-to-siemens-xcelerator-and-the-digital-twin)\n",
            "\n",
            "Siemens is a German multinational conglomerate. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = remote_app.query(query=\"Who is on the board of Siemens?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "vertexAIreasoning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
